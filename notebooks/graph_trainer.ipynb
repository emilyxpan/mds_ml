{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d370b8db-d3a4-4077-8c75-84844c1ad30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import torch\n",
    "from torch.utils.data import Dataset, ConcatDataset, random_split\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d81ee1-1bab-4d1d-953c-481448e7c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileset = {}\n",
    "\n",
    "sig_dir = '/mdsmlvol/rechits_v4/point_clouds/'\n",
    "fileset['sample'] = [sig_dir + f'BToKPhi_MuonLLPDecayGenFilter_PhiToPi0Pi0_mPhi0p3_ctau300_{str(i).zfill(7)}_point_clouds.pt' for i in range(328)]\n",
    "# fileset['sample'] = [sig_dir + f'BToKPhi_MuonLLPDecayGenFilter_PhiToPi0Pi0_mPhi0p3_ctau300_{str(i).zfill(7)}_graphs.pt' for i in range(2)]\n",
    "\n",
    "# bkg_dir = '/ceph/cms/store/user/aaportel/B-Parking/rechits_v2/ParkingBPH1_2018A/'\n",
    "# fileset['background'] = [bkg_dir + f'ParkingBPH1_2018A_{str(i).zfill(7)}.root' for i in range(380)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "006558ff-ca5f-4f32-b29a-38ec13c00e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "split_ratio = 0.8  # 80% of the data for training, 20% for testing\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "datasets = [torch.load(fp) for fp in fileset['sample']]\n",
    "dataset = ConcatDataset(datasets)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(split_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, shuffle=shuffle_dataset)\n",
    "test_loader = DataLoader(test_dataset, shuffle=shuffle_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b49352e-efeb-4463-bdfb-d423178e0d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGCNN(\n",
      "  (input_bn): BatchNorm(17)\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): DynamicEdgeConv(nn=Sequential(\n",
      "      (0): Linear(in_features=34, out_features=64, bias=True)\n",
      "      (1): BatchNorm(64)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (4): BatchNorm(64)\n",
      "      (5): ReLU()\n",
      "    ), k=20)\n",
      "    (1): DynamicEdgeConv(nn=Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): BatchNorm(128)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (4): BatchNorm(128)\n",
      "      (5): ReLU()\n",
      "    ), k=20)\n",
      "    (2): DynamicEdgeConv(nn=Sequential(\n",
      "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (1): BatchNorm(256)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (4): BatchNorm(256)\n",
      "      (5): ReLU()\n",
      "    ), k=20)\n",
      "  )\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import DynamicEdgeConv, global_mean_pool, BatchNorm\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "settings = {\n",
    "    \"k\": 20,\n",
    "    \"input_features\": 17,\n",
    "    \"hidden_units\": [64, 128, 256],\n",
    "    \"fc_units\": [256, 128],\n",
    "    \"dropout\": 0.5,\n",
    "    \"output_classes\": 2,\n",
    "}\n",
    "\n",
    "class DGCNN(torch.nn.Module):\n",
    "    def __init__(self, settings):\n",
    "        super(DGCNN, self).__init__()\n",
    "        self.k = settings['k']\n",
    "        self.input_bn = BatchNorm(settings['input_features'])\n",
    "\n",
    "        # DGCNN uses a series of Dynamic Edge Convolutions\n",
    "        self.conv_layers = torch.nn.ModuleList()\n",
    "        in_channels = settings['input_features']\n",
    "        for out_channels in settings['hidden_units']:\n",
    "            conv = DynamicEdgeConv(\n",
    "                torch.nn.Sequential(\n",
    "                    torch.nn.Linear(2 * in_channels, out_channels),\n",
    "                    BatchNorm(out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(out_channels, out_channels),\n",
    "                    BatchNorm(out_channels),\n",
    "                    torch.nn.ReLU()\n",
    "                ), k=self.k, aggr='max'\n",
    "            )\n",
    "            self.conv_layers.append(conv)\n",
    "            in_channels = out_channels\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        prev_channels = in_channels\n",
    "        for units in settings['fc_units']:\n",
    "            self.fc_layers.append(\n",
    "                torch.nn.Sequential(\n",
    "                    torch.nn.Linear(prev_channels, units),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Dropout(p=settings['dropout'])\n",
    "                )\n",
    "            )\n",
    "            prev_channels = units\n",
    "\n",
    "        # Output layer\n",
    "        self.out = torch.nn.Linear(prev_channels, settings['output_classes'])\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, pos, batch = data.x, data.pos, data.batch\n",
    "\n",
    "        x = self.input_bn(x)\n",
    "        for conv in self.conv_layers:\n",
    "            # The EdgeConv layers now take only x and batch as input\n",
    "            x = conv(x, batch)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        for fc in self.fc_layers:\n",
    "            x = fc(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        return torch.nn.functional.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "model = DGCNN(settings).to(DEVICE)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "712b99d9-325f-4b92-a0d0-86cef3d74f8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DynamicEdgeConv.forward() takes from 2 to 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 12\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Output examination\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/conda/envs/mlllp/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/mlllp/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 59\u001b[0m, in \u001b[0;36mDGCNN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_bn(x)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_layers:\n\u001b[0;32m---> 59\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m x \u001b[38;5;241m=\u001b[39m global_mean_pool(x, batch)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_layers:\n",
      "File \u001b[0;32m/opt/conda/envs/mlllp/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/mlllp/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: DynamicEdgeConv.forward() takes from 2 to 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# Assuming train_loader is already created as per your code\n",
    "\n",
    "# Get a single batch of data\n",
    "data = next(iter(train_loader))\n",
    "\n",
    "# Move data to the same device as the model\n",
    "data = data.to(DEVICE)\n",
    "\n",
    "# Forward pass through the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "\n",
    "# Output examination\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output values:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda11ce-d6d8-41b3-a46e-a60d6da612db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
